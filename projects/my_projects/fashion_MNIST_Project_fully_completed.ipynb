{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fashion-MNIST is a dataset of Zalando's (http://www.zalando.com) article images â€”consisting of a training set of 60,000 examples\n",
    "and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. \n",
    "Fashion-MNIST serves as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms.\n",
    "It shares the same image size and structure of training and testing splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np    \n",
    "import pandas as pd\n",
    "import gzip\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(data):\n",
    "    some_article = data   # Selecting the image.\n",
    "    some_article_image = some_article.reshape(28, 28) # Reshaping it to get the 28x28 pixels\n",
    "    plt.imshow(some_article_image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data from my local folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath_train_set = (r'C:\\Users\\jhach\\Desktop\\datasets/train-images-idx3-ubyte.gz')\n",
    "filePath_train_label = (r'C:\\Users\\jhach\\Desktop\\datasets/train-labels-idx1-ubyte.gz')\n",
    "filePath_test_set = (r'C:\\Users\\jhach\\Desktop\\datasets/t10k-images-idx3-ubyte.gz')\n",
    "filePath_test_label = (r'C:\\Users\\jhach\\Desktop\\datasets/t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n",
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "with gzip.open(filePath_train_label, 'rb') as trainLbpath:\n",
    "     trainLabel = np.frombuffer(trainLbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "with gzip.open(filePath_train_set, 'rb') as trainSetpath:\n",
    "     trainSet = np.frombuffer(trainSetpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(trainLabel), 784)\n",
    "\n",
    "with gzip.open(filePath_test_label, 'rb') as testLbpath:\n",
    "     testLabel = np.frombuffer(testLbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "with gzip.open(filePath_test_set, 'rb') as testSetpath:\n",
    "     testSet = np.frombuffer(testSetpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(testLabel), 784)\n",
    "\n",
    "print(type(testLabel))\n",
    "\n",
    "print(trainSet.shape)\n",
    "\n",
    "print(trainLabel.shape)\n",
    "\n",
    "print(testSet.shape)\n",
    "\n",
    "print(testLabel.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = trainSet, testSet, trainLabel, testLabel\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset consists of 60,000 images and each image has 784 features. An image consists of 28x28 pixels, and each pixel is a value from 0 to 255 describing the pixel intensity. 0 for white and 255 for black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showImage(X_train[60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffling the training dataset - to get uniform samples for cross validation\n",
    "\n",
    "We need to shuffle our training data to ensure that we don't miss out any digit in a cross validation fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling the data\n",
    "np.random.seed(42)\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image (instance) in the dataset has 784 pixels (features) and value of each feature(pixel) ranges from 0 to 255, \n",
    "and this range is too wide , hence we would need to use feature scaling here to apply standardization to this dataset X_train,\n",
    "so that all the values of each feature (pixel) is in a small range (based on the standard deviation value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying SGDClassifier model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training SGDClassifier model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = sgd_clf.predict(X_train[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train_predict[0]\n",
    "showImage(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us predict all instances of training dataset X_train_scaled using the above trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Accuracy:  0.8460833333333333\n",
      "SGD Precision:  0.8452191984816628\n",
      "SGD Recall:  0.8460833333333333\n",
      "SGD F1 Score:  0.8438106231931057\n"
     ]
    }
   ],
   "source": [
    "y_train_predict = sgd_clf.predict(X_train_scaled)\n",
    "sgd_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "sgd_precision = precision_score(y_train, y_train_predict, average='weighted')\n",
    "sgd_recall = recall_score(y_train, y_train_predict, average='weighted')\n",
    "sgd_f1_score = f1_score(y_train, y_train_predict, average='weighted')\n",
    "print(\"SGD Accuracy: \", sgd_accuracy)\n",
    "print(\"SGD Precision: \", sgd_precision)\n",
    "print(\"SGD Recall: \", sgd_recall)\n",
    "print(\"SGD F1 Score: \", sgd_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us try LogisticRegression\n",
    "\n",
    "Since this is multi-class problem (we need to predict multiple classes (0,1,2...9) for the given label), hence we will use\n",
    "Softmax Regression, which is nothing but Logistic Regression for multi-class classification problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=42, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_clf = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", C=10, random_state=42)\n",
    "log_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = log_clf.predict(X_train[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showImage(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Accuracy:  0.8775333333333334\n",
      "Logistic Precision:  0.876648632278309\n",
      "Logistic Recall:  0.8775333333333334\n",
      "Logistic F1 Score:  0.8769281105807729\n"
     ]
    }
   ],
   "source": [
    "y_train_predict = log_clf.predict(X_train_scaled)\n",
    "\n",
    "log_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "log_precision = precision_score(y_train, y_train_predict, average='weighted')\n",
    "log_recall = recall_score(y_train, y_train_predict, average='weighted')\n",
    "log_f1_score = f1_score(y_train, y_train_predict, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Logistic Accuracy: \", log_accuracy)\n",
    "print(\"Logistic Precision: \", log_precision)\n",
    "print(\"Logistic Recall: \", log_recall)\n",
    "print(\"Logistic F1 Score: \", log_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us try DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=50,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training DecisionTreeClassifier model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dec_tree_clf = DecisionTreeClassifier(max_depth=50, random_state=42)\n",
    "dec_tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = dec_tree_clf.predict(X_train[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showImage(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy:  1.0\n",
      "Decision Tree Precision:  1.0\n",
      "Decision Tree Recall:  1.0\n",
      "Decision Tree F1 Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "y_train_predict = dec_tree_clf.predict(X_train)\n",
    "\n",
    "dec_tree_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "dec_tree_precision = precision_score(y_train, y_train_predict, average='weighted')\n",
    "dec_tree_recall = recall_score(y_train, y_train_predict, average='weighted')\n",
    "dec_tree_f1_score = f1_score(y_train, y_train_predict, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Decision Tree Accuracy: \", dec_tree_accuracy)\n",
    "print(\"Decision Tree Precision: \", dec_tree_precision)\n",
    "print(\"Decision Tree Recall: \", dec_tree_recall)\n",
    "print(\"Decision Tree F1 Score: \", dec_tree_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us try RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhach\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# training RandomForestClassifier model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, max_depth=50, random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = rnd_clf.predict(X_train[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showImage(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = rnd_clf.predict(X_train)\n",
    "\n",
    "rnd_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "rnd_precision = precision_score(y_train, y_train_predict, average='weighted')\n",
    "rnd_recall = recall_score(y_train, y_train_predict, average='weighted')\n",
    "rnd_f1_score = f1_score(y_train, y_train_predict, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Random Forest Accuracy: \", rnd_accuracy)\n",
    "print(\"Random Forest Precision: \", rnd_precision)\n",
    "print(\"Random Forest Recall: \", rnd_recall)\n",
    "print(\"Random Forest F1 Score: \", rnd_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us try Ensemble with soft voting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training VotingClassifier model\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "log_clf_ens = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", C=10, random_state=42)\n",
    "rnd_clf_ens = RandomForestClassifier(n_estimators=100, max_depth=50, random_state=42)\n",
    "voting_clf = VotingClassifier(estimators=[('lr', log_clf_ens), ('rf', rnd_clf_ens)],voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = voting_clf.predict(X_train[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showImage(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = voting_clf.predict(X_train_scaled)\n",
    "\n",
    "voting_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "voting_precision = precision_score(y_train, y_train_predict, average='weighted')\n",
    "voting_recall = recall_score(y_train, y_train_predict, average='weighted')\n",
    "voting_f1_score = f1_score(y_train, y_train_predict, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Ensemble Accuracy: \", voting_accuracy)\n",
    "print(\"Ensemble Precision: \", voting_precision)\n",
    "print(\"Ensemble Recall: \", voting_recall)\n",
    "print(\"Ensemble F1 Score: \", voting_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us try XGBClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training XGBClassifier model\n",
    "from xgboost import XGBClassifier\n",
    "xgb_clf = XGBClassifier(n_estimators=20, max_depth=10, random_state=42)\n",
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = xgb_clf.predict(X_train[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showImage(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = xgb_clf.predict(X_train)\n",
    "xgb_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "xgb_precision = precision_score(y_train, y_train_predict, average='weighted')\n",
    "xgb_recall = recall_score(y_train, y_train_predict, average='weighted')\n",
    "xgb_f1_score = f1_score(y_train, y_train_predict, average='weighted')\n",
    "\n",
    "\n",
    "print(\"XGBoost Accuracy: \", xgb_accuracy)\n",
    "print(\"XGBoost Precision: \", xgb_precision)\n",
    "print(\"XGBoost Recall: \", xgb_recall)\n",
    "print(\"XGBoost F1 Score: \", xgb_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us use cross validation to find the proper score of each model, also to ensure that the model is not overfitting or underfitting.\n",
    "If the cross validation score values for a performance measure (say accuracy) are not varying significantly for various folds (k-folds) then we can say that the model is not overfitting.\n",
    "If the cross validation score values for a performance measure (say accuracy) are not very low for various folds (k-folds) then we can say that the model is not underfitting.\n",
    "We will perform k-fold cross-validation\n",
    "Will randomly split the training set into 3 distinct subsets called folds (cv=3). Since cross validation is a computing intensive and time consuming process, we are limiting 'cv' (no. of folds) to 3 instead of normally 10 folds.\n",
    "Then will train and evaluate each model 3 times by picking a different fold for evaluation every time and training on the other 2 folds\n",
    "The result will be an array containing the 3 evaluation scores for each of the measures - accuracy, precision, F1 score.\n",
    "We will use cross_val_score() function to calculate accuracy\n",
    "But accuracy is generally not the preferred performance measure for classifiers, especially when you are dealing with skewed datasets.\n",
    "A dataset is said to be skewed when some classes are much more frequent than others.\n",
    "Even if the current training dataset may not be skewed, the future test dataset (live) on which the model runs can be skewed, hence, considering we may get skewed dataset in future, let us calculate Precision, Recall and F1 score also for the models.\n",
    "And will use cross_val_predict() function to create confusion matrix to calculate Precision, Recall and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate mean and standard deviation of each score (e.g. accuracy, precision, etc.)\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "    \n",
    "    \n",
    "#Selecting the Model - Cross-Validation - SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us calculate accuracy, precision, recall, F1 score for SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = SGDClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_cv_scores = cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scores(sgd_cv_scores)\n",
    "sgd_cv_accuracy = sgd_cv_scores.mean()\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
    "confusion_matrix(y_train, y_train_pred)\n",
    "sgd_cv_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "sgd_cv_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "sgd_cv_f1_score = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "print(\"SGD CV Accuracy: \", sgd_cv_accuracy)\n",
    "print(\"SGD CV Precision: \", sgd_cv_precision)\n",
    "print(\"SGD CV Recall: \", sgd_cv_recall)\n",
    "print(\"SGD CV F1 Score: \", sgd_cv_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above, SGDClassifier gives accuracy of 83.35% (standrad deviation = 0.0020), precision, recall and F1 score of 83.19%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us calculate accuracy, precision, recall, F1 Score for Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the Model - Cross-Validation - Softmax Regression\n",
    "log_clf = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", C=10, random_state=42\n",
    ") \n",
    "\n",
    "log_cv_scores = cross_val_score(log_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\") \n",
    "display_scores(log_cv_scores)\n",
    "log_cv_accuracy = log_cv_scores.mean()\n",
    "\n",
    "y_train_pred = cross_val_predict(log_clf, X_train_scaled, y_train, cv=3)\n",
    "confusion_matrix(y_train, y_train_pred)\n",
    "log_cv_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "log_cv_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "log_cv_f1_score = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "print(\"Logistic CV Accuracy: \", log_cv_accuracy)\n",
    "print(\"Logistic CV Precision: \", log_cv_precision)\n",
    "print(\"Logistic CV Recall: \", log_cv_recall)\n",
    "print(\"Logistic CV F1 Score: \", log_cv_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above, Softmax Regression (with parameters - multi_class=\"multinomial\", solver=\"lbfgs\" and C=10) gives accuracy of 84.70% (standrad deviation = 0.0022), precision, recall and F1 score of 84.58%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us calculate accuracy, precision, recall, F1 Score for DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled Features not required for Decision Tree\n",
    "dec_tree_scores = cross_val_score(dec_tree_clf, X_train, y_train, cv=3, scoring=\"accuracy\") \n",
    "display_scores(dec_tree_scores)\n",
    "dec_tree_accuracy = dec_tree_scores.mean()\n",
    "\n",
    "y_train_pred = cross_val_predict(dec_tree_clf, X_train, y_train, cv=3)\n",
    "confusion_matrix(y_train, y_train_pred)\n",
    "dec_tree_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "dec_tree_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "dec_tree_f1_score = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "print(\"Decision Tree CV Accuracy: \", dec_tree_accuracy)\n",
    "print(\"Decision Tree CV Precision: \", dec_tree_precision)\n",
    "print(\"Decision Tree CV Recall: \", dec_tree_precision)\n",
    "print(\"Decision Tree CV F1 Score: \", dec_tree_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above, Decision Tree Classifier (with parameter - max_depth=50) gives accuracy of 78.94% (standrad deviation = 0.0016), precision, recall and F1 score of 78.94%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us calculate accuracy, precision, recall, F1 score for RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled features not required for Random Forest (as it is based on Decision Trees)\n",
    "\n",
    "def calculateRandomForestScores():\n",
    "    rnd_scores = cross_val_score(rnd_clf, X_train, y_train, cv=3, scoring=\"accuracy\") \n",
    "    display_scores(rnd_scores)\n",
    "    rnd_accuracy = rnd_scores.mean()\n",
    "\n",
    "    y_train_pred = cross_val_predict(rnd_clf, X_train, y_train, cv=3)\n",
    "    confusion_matrix(y_train, y_train_pred)\n",
    "    rnd_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "    rnd_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "    rnd_f1_score = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "    print(\"Random Forest CV Accuracy: \", rnd_accuracy)\n",
    "    print(\"Random Forest CV Precision: \", rnd_precision)\n",
    "    print(\"Random Forest CV Recall: \", rnd_precision)\n",
    "    print(\"Random Forest CV F1 Score: \", rnd_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateRandomForestScores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above, Random Forest Classifier (with parameters - no. of estimators=100 and max_depth=50) gives accuracy of 88.05% (standard deviation = 0.0023), precision, recall and F1 score of 87.95%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us calculate accuracy, precision, recall, F1 score for Ensemble (Voting Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateEnsembleScores():\n",
    "    voting_scores = cross_val_score(voting_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\") \n",
    "    display_scores(voting_scores)\n",
    "    voting_accuracy = voting_scores.mean()\n",
    "\n",
    "    y_train_pred = cross_val_predict(voting_clf, X_train_scaled, y_train, cv=3)\n",
    "    confusion_matrix(y_train, y_train_pred)\n",
    "    voting_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "    voting_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "    voting_f1_score = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "    print(\"Ensemble CV Accuracy: \", voting_accuracy)\n",
    "    print(\"Ensemble CV Precision: \", voting_precision)\n",
    "    print(\"Ensemble CV Recall: \", voting_precision)\n",
    "    print(\"Ensemble CV F1 Score: \", voting_f1_score)\n",
    "    \n",
    "calculateEnsembleScores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above, Ensemble (of Softmax Regression and Random Forest) with soft voting and no. of estimators as 100 and max_depth as 50, we are getting accuracy of 87.14%, and precision, recall and F1 score of 87%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try Ensemble with lesser no. of estimators and max_depth (no. of estimators = 20, max_depth=10), and see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "log_clf_ens = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", C=10, random_state=42)\n",
    "rnd_clf_ens = RandomForestClassifier(n_estimators=20, max_depth=10, random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf_ens), ('rf', rnd_clf_ens)],\n",
    "    voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateEnsembleScores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above, Ensemble (of Softmax Regression and Random Forest with soft voting) with no. of estimators as 20 and max_depth as 10 gives accuracy of 86.36% (standrad deviation = 0.0026), precision, recall and F1 score of 86.19%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier, for the same Ensemble with no. of estimators as 100 and max_depth as 50 we got accuracy of 87.14% (standard deviation = 0.0026), and precision, recall and F1 score of 87%.\n",
    "\n",
    "We see that, for the same Ensemble, by increasing the no. of estimators and max_depth, we are getting better scores.\n",
    "\n",
    "Hence, probably, by adding some more algorithms (models) to the Ensemble, and by trying tuning a few more parameter values, we may be able to improve the scores further.\n",
    "\n",
    "\n",
    "Up to this point, we see that, Random Forest has performed better than all other algorithms(including Ensemble) that we used so far.\n",
    "\n",
    "Now, let us compare Random Forest with XGBoost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us calculate accuracy, precision, recall, F1 Score for XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled features not required for XGBoost (as it is based on Decision Trees)\n",
    "xgb_scores = cross_val_score(xgb_clf, X_train, y_train, cv=3, scoring=\"accuracy\") \n",
    "display_scores(xgb_scores)\n",
    "xgb_accuracy = xgb_scores.mean()\n",
    "\n",
    "y_train_pred = cross_val_predict(xgb_clf, X_train, y_train, cv=3)\n",
    "confusion_matrix(y_train, y_train_pred)\n",
    "xgb_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "xgb_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "xgb_f1_score = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "print(\"XGBoost CV Accuracy: \", xgb_accuracy)\n",
    "print(\"XGBoost CV Precision: \", xgb_precision)\n",
    "print(\"XGBoost CV Recall: \", xgb_precision)\n",
    "print(\"XGBoost CV F1 Score: \", xgb_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above, XGBoost Classifier (with parameters - no. of estimators=20 and max_depth=10) gives accuracy of 87.62% (standard deviation = 0.00063), precision, recall and F1 score of 87.53%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us compare the XGBoost scores with that of Random Forest for the same set of parameter values (no. of estimators=20 and max_depth=10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=20, max_depth=10, random_state=42)\n",
    "# Scaling is not needed for Decision Tree algorithm and hence for Random Forest and XGBoost algorithms as they \n",
    "# are also based on Decision Trees. Hence, not using scaled training dataset here\n",
    "rnd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateRandomForestScores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, for the same set of parameter values (n_estimators=20, max_depth=10), scores of XGBoost are better than that of Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest:\n",
    "Accuracy: 84.82\n",
    "Standard Deviation: 0.0024\n",
    "Precision, Recall, F1 Score: 84.82\n",
    "\n",
    "\n",
    "XGBoost:\n",
    "Accuracy: 87.62\n",
    "Standard Deviation: 0.00063\n",
    "Precision, Recall, F1 Score: 87.53"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we conclude that XGBoost performance is the best for this problem, hence, we select XGBoost as our final model and will proceed with fine-tuning the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search takes a lot of time on large datasets. Let us apply Dimensionality Reduction to the training dataset to reduce the number of features in the dataset, so that the time taken for grid search and prediction is reduced. Also, we will calculate the scores based on the reduced features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see, if dimensionality reduction leads to any significant loss of information from the images in our training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we get a significant loss of information with dimensionality reduction, we will not use dimensionality reduction for our training dataset (and hence the problem)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using Projection technique for dimensionality reduction for our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use Scikit Learn's PCA class which uses SVD \n",
    "# (Singular Value Decomposition) internally and also the projection\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# with n_components=0.95, in the reduced dataset (X_train_reduced) we got only 187 features (out of original 784)\n",
    "# , and there was significant loss of information (quality) in the 'recovered' (decompressed) images.\n",
    "# Hence, I have selected n_components=0.99, which gives 459 features (out of original 784) \n",
    "# and there is no significant loss of information (quality) in the 'recovered' images \n",
    "\n",
    "pca = PCA(n_components=0.99)\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if hit your 99% minimum?\n",
    "np.sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us recover (decompress) one of the images (instance) of X_train_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use inverse_transform to decompress back to 784 dimensions\n",
    "\n",
    "X_train_recovered = pca.inverse_transform(X_train_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_digits(instances, images_per_row=5, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary, **options)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.subplot(121)\n",
    "# Plotting 'original' image\n",
    "plot_digits(X_train[::2100])\n",
    "plt.title(\"Original\", fontsize=16)\n",
    "plt.subplot(122)\n",
    "# Plotting the corresponding 'recovered' image\n",
    "plot_digits(X_train_recovered[::2100])\n",
    "plt.title(\"Compressed\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning the selected XGBoost classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By applying dimensionality reduction (with variance ratio of 0.99 i.e. n_components=0.99), we don't get any significant loss of information(quality) in the resulting X_train_reduced dataset. Hence, we will use the X_train_reduced (dimensionally reduced dataset) for grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    # try (1x3)=3 combinations of hyperparameters\n",
    "    {'n_estimators': [20], 'max_depth': [8, 10, 12]},\n",
    "    \n",
    "]\n",
    "\n",
    "xgb_clf_grid_search = XGBClassifier(random_state=42)\n",
    "# train across 3 folds, that's a total of 3x3=9 rounds of training \n",
    "grid_search = GridSearchCV(xgb_clf_grid_search, param_grid, cv=3,\n",
    "                           scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best hyperparameter combinations\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best estimator\n",
    "\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the score of each hyperparameter combination used during the grid search\n",
    "\n",
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us evaluate our selected XGBoost model, using best parameters, on the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't get significant loss of information by applying dimensionality reduction on training dataset, then apply dimensionality reduction on your test dataset(X_test) to get X_test_reduced dataset (dimensionally reduced dataset) and use the X_test_reduced (dimensionally reduced dataset) for evaluating the model on test dataset (X_test_reduced), else, use original test dataset X_test for evaluating the model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on the test Set\n",
    "\n",
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Remember, you have to use pca object of training dataset (you got on training dataset during dimensionality reduction)\n",
    "# and only apply transform on test dataset (not fit_transform) - highly important\n",
    "\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "\n",
    "\n",
    "y_test_predict = final_model.predict(X_test_reduced)\n",
    "\n",
    "\n",
    "confusion_matrix(y_test, y_test_predict)\n",
    "final_accuracy = accuracy_score(y_test, y_test_predict)\n",
    "final_precision = precision_score(y_test, y_test_predict, average='weighted')\n",
    "final_recall = recall_score(y_test, y_test_predict, average='weighted')\n",
    "final_f1_score = f1_score(y_test, y_test_predict, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Final Accuracy: \", final_accuracy)\n",
    "print(\"Final Precision: \", final_precision)\n",
    "print(\"Final Recall: \", final_precision)\n",
    "print(\"Final F1 Score: \", final_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showImage(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
